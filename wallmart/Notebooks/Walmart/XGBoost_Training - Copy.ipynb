{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1762cff4-ca8f-4157-9ce5-1a12654538ee",
   "metadata": {},
   "source": [
    "*Training an XGBoost model on the Walmart Daily data to identify anomalies in it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014099b7-0b55-474d-bf58-f2ea3e39baba",
   "metadata": {},
   "source": [
    "# Start"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0839c5-2471-4e29-948e-66c0a2531c49",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4c0facc-e467-4ac1-b768-64a33a515005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib\n",
    "import datetime \n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfcce45d-b12b-48d6-979d-44fbbbdd0d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_folder = 'C:\\\\Geeta\\\\learning\\\\projects\\\\AnomalyDetectionSXM\\\\Notebooks\\\\Datasets\\\\Pipeline'\n",
    "dataset_name = 'Walmart_Weekly'\n",
    "train_file = base_folder + '/train/' + dataset_name +'_train.csv'\n",
    "inference_file = base_folder + '/inference/' + dataset_name +'_inference.csv'\n",
    "\n",
    "current_date_time = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "model_file_path = base_folder + '/xgboostADmodel_' + dataset_name + current_date_time + '.pkl'\n",
    "\n",
    "inference_results_file = base_folder + '/inference/' + dataset_name +'_inference_results.csv'\n",
    "\n",
    "target = 'Weekly_Sales'\n",
    "# target = 'Daily_Sales'\n",
    "\n",
    "# Group the data by 'State' and perform lag shifting within each group\n",
    "groupby_cols=['State'] \n",
    "\n",
    "# Define lag columns to consider\n",
    "lag_columns = ['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "\n",
    "# Define the lag values to be used\n",
    "lags = [1, 2, 4]  # Example lag values of 1 week and 2 weeks\n",
    "\n",
    "state_encoder = 'label_encoder_State.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67beef6d-740c-4094-8b1f-96fa3c201a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = train_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28797162-5f06-47f0-8a0e-6d6952b1e53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Geeta\\\\learning\\\\projects\\\\AnomalyDetectionSXM\\\\Notebooks\\\\Datasets\\\\Pipeline/train/Walmart_Weekly_train.csv'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c853fd3a-b9ef-4d6b-8e8b-46b94d2e999d",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38e96464-953a-401e-a6fb-8f5d32a1bb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read(data_path, sheet_name = '', usecols = None):\n",
    "    df = pd.DataFrame()\n",
    "    if data_path.split('.')[-1] == 'xlsx':\n",
    "        if sheet_name:\n",
    "            df = pd.read_excel(data_path, sheet_name=sheet_name, usecols=usecols)\n",
    "        else:\n",
    "            df = pd.read_excel(data_path, usecols=usecols)\n",
    "        print(\"Shape of the data in file {} is {}\".format(data_path, df.shape))\n",
    "    else:\n",
    "        try:\n",
    "            df = pd.read_csv(data_path)\n",
    "            print(\"Shape of the data in file {} is {}\".format(data_path, df.shape))\n",
    "            if df.shape[0] == 0:\n",
    "                print(\"No data in file {}\".format(data_path))\n",
    "        except Exception as e:\n",
    "            print(\"Issue while reading data at {} \\n{}\".format(data_path, e))\n",
    "    return df\n",
    "\n",
    "\n",
    "def standardize_date_col(dataframe, date_col):\n",
    "    dataframe[date_col] = pd.to_datetime(dataframe[date_col], infer_datetime_format=True) #.fillna(pd.to_datetime(df['Date'], format='%d/%m/%y', errors='coerce'))\n",
    "    # dataframe[date_col] = pd.to_datetime(dataframe[date_col], format='%Y-%m-%d', errors='coerce')#.fillna(pd.to_datetime(df['Date'], format='%d/%m/%y', errors='coerce'))\n",
    "    # Convert all dates to 'mm-dd-yyyy' format\n",
    "    # dataframe[date_col] = dataframe[date_col].dt.strftime('%Y-%m-%d')\n",
    "    return dataframe\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e54ea7e-d096-41d9-9275-6a894a37eba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the data in file C:\\Geeta\\learning\\projects\\AnomalyDetectionSXM\\Notebooks\\Datasets\\Pipeline/train/Walmart_Weekly_train.csv is (710, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Sales_Amount_Upper</th>\n",
       "      <th>Sales_Amount_Lower</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-02-05</td>\n",
       "      <td>10397622.73</td>\n",
       "      <td>37.20</td>\n",
       "      <td>2.58</td>\n",
       "      <td>200.61</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11573691.83</td>\n",
       "      <td>9513064.59</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-02-12</td>\n",
       "      <td>10378496.65</td>\n",
       "      <td>36.72</td>\n",
       "      <td>2.55</td>\n",
       "      <td>200.74</td>\n",
       "      <td>7.55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11032180.28</td>\n",
       "      <td>8971553.04</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-02-19</td>\n",
       "      <td>10060556.61</td>\n",
       "      <td>39.70</td>\n",
       "      <td>2.52</td>\n",
       "      <td>200.79</td>\n",
       "      <td>7.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10763335.98</td>\n",
       "      <td>8702708.74</td>\n",
       "      <td>Florida</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Weekly_Sales  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
       "0 2021-02-05   10397622.73        37.20        2.58  200.61          7.55   \n",
       "1 2021-02-12   10378496.65        36.72        2.55  200.74          7.55   \n",
       "2 2021-02-19   10060556.61        39.70        2.52  200.79          7.55   \n",
       "\n",
       "   Holiday_Flag  Anomaly  Sales_Amount_Upper  Sales_Amount_Lower    State  \n",
       "0             0        0         11573691.83          9513064.59  Florida  \n",
       "1             1        0         11032180.28          8971553.04  Florida  \n",
       "2             0        0         10763335.98          8702708.74  Florida  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data from csv or excel, sheet_name is the sheet in excel that contians data \n",
    "data = read(data_path, sheet_name= 'RAW')\n",
    "data = standardize_date_col(data, 'Date')\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924ccfcb-93b7-479d-bfb7-9b933a6c22c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by the 'Date' column in ascending order\n",
    "data = data.sort_values('Date')\n",
    "data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ceac9604-a065-4943-a29b-98c11ef795eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI',\n",
       "       'Unemployment', 'Holiday_Flag', 'Anomaly', 'Sales_Amount_Upper',\n",
       "       'Sales_Amount_Lower', 'State'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3ae2d-beb3-4fae-8b01-b7ff75b4dbd9",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d22ff78-b5e9-4c63-ac33-543c00198c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lag_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d40b920-c36c-4f3b-bf70-b6dc5f48f3a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(710, 271)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_lag_columns(data, groupby_cols, lag_columns):\n",
    "    # Group the data by 'State' and perform lag shifting within each group\n",
    "    grouped = data.groupby(groupby_cols)\n",
    "    \n",
    "    \n",
    "    # Create lag features within each group\n",
    "    for lag in lags:\n",
    "        for col in lag_columns:\n",
    "            data[f'{col}_lag_{lag}'] = grouped[col].shift(lag)\n",
    "            data[f'{col}_lag_{lag}'] = data[f'{col}_lag_{lag}'].bfill()\n",
    "    print(\"Before dropping NAs:\", data.shape)\n",
    "    data.dropna(inplace=True)\n",
    "    print(\"After dropping NAs:\", data.shape)\n",
    "    return data\n",
    "\n",
    "def get_lag_Weekly_Sales(data, groupby_cols, lag_columns):\n",
    "    # Group the data by 'State' and perform lag shifting within each group\n",
    "    group = data.groupby(groupby_cols)\n",
    "    \n",
    "    # Create lagged features\n",
    "    for col in lag_columns:\n",
    "        for i in range(52, 0, -1):\n",
    "            data[col + '_' +str(i)] = group[col].shift(i)\n",
    "    return data\n",
    "        \n",
    "    \n",
    "# data = get_lag_columns(data, groupby_cols, lag_columns)\n",
    "data = get_lag_Weekly_Sales(data, groupby_cols, lag_columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecdb7066-6ed0-4882-8070-b8b6fae5bcea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(450, 271)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de41a44c-4be1-4fb1-8335-6a737e12af75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI',\n",
       "       'Unemployment', 'Holiday_Flag', 'Anomaly', 'Sales_Amount_Upper',\n",
       "       'Sales_Amount_Lower',\n",
       "       ...\n",
       "       'Unemployment_10', 'Unemployment_9', 'Unemployment_8', 'Unemployment_7',\n",
       "       'Unemployment_6', 'Unemployment_5', 'Unemployment_4', 'Unemployment_3',\n",
       "       'Unemployment_2', 'Unemployment_1'],\n",
       "      dtype='object', length=271)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "95597b8a-2b8d-475d-96c2-ace9faf15c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_date_features(data, date_col):\n",
    "    def week_of_month(date):\n",
    "        # Get the first day of the month\n",
    "        first_day = date.replace(day=1)\n",
    "        # Calculate the adjusted day of the week (0=Monday, ..., 6=Sunday)\n",
    "        adjusted_dom = (first_day.weekday() + 1) % 7\n",
    "        # Calculate the week of the month\n",
    "        week_of_month = (date.day + adjusted_dom - 1) // 7 + 1\n",
    "        return week_of_month\n",
    "    \n",
    "    data['Week_Of_Month'] = data[date_col].map(week_of_month)\n",
    "    # Create time-based features\n",
    "    data[date_col] = pd.to_datetime(data[date_col])\n",
    "    # data['Day_of_Week'] = data['Date'].dt.dayofweek  # Day of the week (0: Monday, 1: Tuesday, ..., 6: Sunday)\n",
    "    data['Month'] = data[date_col].dt.month  # Month of the year (1 to 12)\n",
    "    data['Quarter'] = data[date_col].dt.quarter  # Quarter of the year (1 to 4)\n",
    "    data['Year'] = data[date_col].dt.year  # Year\n",
    "    return data\n",
    "\n",
    "data = get_date_features(data, 'Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07b9bed7-8c93-4b8e-a943-563c438cdacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Sales_Amount_Upper</th>\n",
       "      <th>Sales_Amount_Lower</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment_6</th>\n",
       "      <th>Unemployment_5</th>\n",
       "      <th>Unemployment_4</th>\n",
       "      <th>Unemployment_3</th>\n",
       "      <th>Unemployment_2</th>\n",
       "      <th>Unemployment_1</th>\n",
       "      <th>Week_Of_Month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2022-11-18</td>\n",
       "      <td>11153431.69</td>\n",
       "      <td>47.82</td>\n",
       "      <td>3.56</td>\n",
       "      <td>155.31</td>\n",
       "      <td>8.01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13506883.25</td>\n",
       "      <td>11425613.90</td>\n",
       "      <td>...</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>8.01</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>562</th>\n",
       "      <td>2023-03-31</td>\n",
       "      <td>9908450.93</td>\n",
       "      <td>65.74</td>\n",
       "      <td>3.83</td>\n",
       "      <td>210.06</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11640852.67</td>\n",
       "      <td>9580225.42</td>\n",
       "      <td>...</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>2023-03-10</td>\n",
       "      <td>10291510.29</td>\n",
       "      <td>53.28</td>\n",
       "      <td>3.63</td>\n",
       "      <td>209.75</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11368810.47</td>\n",
       "      <td>9308183.23</td>\n",
       "      <td>...</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>2023-03-24</td>\n",
       "      <td>9664462.49</td>\n",
       "      <td>58.94</td>\n",
       "      <td>3.77</td>\n",
       "      <td>209.97</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11291870.79</td>\n",
       "      <td>9231243.55</td>\n",
       "      <td>...</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>2022-06-03</td>\n",
       "      <td>11421205.89</td>\n",
       "      <td>68.15</td>\n",
       "      <td>3.87</td>\n",
       "      <td>153.68</td>\n",
       "      <td>8.36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12020871.82</td>\n",
       "      <td>9939602.47</td>\n",
       "      <td>...</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.36</td>\n",
       "      <td>8.36</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Weekly_Sales  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
       "466 2022-11-18   11153431.69        47.82        3.56  155.31          8.01   \n",
       "562 2023-03-31    9908450.93        65.74        3.83  210.06          6.41   \n",
       "549 2023-03-10   10291510.29        53.28        3.63  209.75          6.41   \n",
       "556 2023-03-24    9664462.49        58.94        3.77  209.97          6.41   \n",
       "349 2022-06-03   11421205.89        68.15        3.87  153.68          8.36   \n",
       "\n",
       "     Holiday_Flag  Anomaly  Sales_Amount_Upper  Sales_Amount_Lower  ...  \\\n",
       "466             0        1         13506883.25         11425613.90  ...   \n",
       "562             0        0         11640852.67          9580225.42  ...   \n",
       "549             0        0         11368810.47          9308183.23  ...   \n",
       "556             0        0         11291870.79          9231243.55  ...   \n",
       "349             0        0         12020871.82          9939602.47  ...   \n",
       "\n",
       "    Unemployment_6  Unemployment_5  Unemployment_4  Unemployment_3  \\\n",
       "466           8.01            8.01            8.01            8.01   \n",
       "562           6.41            6.41            6.41            6.41   \n",
       "549           6.41            6.41            6.41            6.41   \n",
       "556           6.41            6.41            6.41            6.41   \n",
       "349           8.36            8.36            8.36            8.36   \n",
       "\n",
       "     Unemployment_2  Unemployment_1  Week_Of_Month  Month  Quarter  Year  \n",
       "466            8.01            8.01              3     11        4  2022  \n",
       "562            6.41            6.41              5      3        1  2023  \n",
       "549            6.41            6.41              2      3        1  2023  \n",
       "556            6.41            6.41              4      3        1  2023  \n",
       "349            8.36            8.36              1      6        2  2022  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea7e37d7-055d-48ad-aa77-33e054b044c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder_State.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encode categorical columns\n",
    "encoder = LabelEncoder()\n",
    "data['State'] = encoder.fit_transform(data['State'])\n",
    "\n",
    "# Save the trained label encoder\n",
    "joblib.dump(encoder, state_encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f00c62-0201-46d4-bd44-8bb82488922f",
   "metadata": {},
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3deee33f-2687-4c0c-b694-bacfff9ae14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop_cols = ['Temperature', 'Fuel_Price', 'CPI', 'Unemployment']\n",
    "# data.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5020ed5-a61e-4f86-8bed-73a5ebaf8438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Anomaly</th>\n",
       "      <th>Sales_Amount_Upper</th>\n",
       "      <th>Sales_Amount_Lower</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment_6</th>\n",
       "      <th>Unemployment_5</th>\n",
       "      <th>Unemployment_4</th>\n",
       "      <th>Unemployment_3</th>\n",
       "      <th>Unemployment_2</th>\n",
       "      <th>Unemployment_1</th>\n",
       "      <th>Week_Of_Month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>2022-10-07</td>\n",
       "      <td>7420671.08</td>\n",
       "      <td>66.94</td>\n",
       "      <td>3.50</td>\n",
       "      <td>167.79</td>\n",
       "      <td>8.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7688144.87</td>\n",
       "      <td>6336700.40</td>\n",
       "      <td>...</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.29</td>\n",
       "      <td>9.29</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>2022-09-09</td>\n",
       "      <td>9553921.17</td>\n",
       "      <td>73.17</td>\n",
       "      <td>3.55</td>\n",
       "      <td>205.24</td>\n",
       "      <td>7.10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10296654.30</td>\n",
       "      <td>8236027.05</td>\n",
       "      <td>...</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>7.10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>11491173.47</td>\n",
       "      <td>33.07</td>\n",
       "      <td>3.74</td>\n",
       "      <td>164.23</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12269936.54</td>\n",
       "      <td>9419068.75</td>\n",
       "      <td>...</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>2023-02-17</td>\n",
       "      <td>11284939.90</td>\n",
       "      <td>42.37</td>\n",
       "      <td>3.46</td>\n",
       "      <td>209.22</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11179403.79</td>\n",
       "      <td>9118776.54</td>\n",
       "      <td>...</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>6.41</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2023-01-13</td>\n",
       "      <td>9710842.80</td>\n",
       "      <td>36.15</td>\n",
       "      <td>3.54</td>\n",
       "      <td>163.71</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12943328.33</td>\n",
       "      <td>10092460.55</td>\n",
       "      <td>...</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.28</td>\n",
       "      <td>7.20</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2023</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 275 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Weekly_Sales  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
       "438 2022-10-07    7420671.08        66.94        3.50  167.79          8.92   \n",
       "416 2022-09-09    9553921.17        73.17        3.55  205.24          7.10   \n",
       "532 2023-02-17   11491173.47        33.07        3.74  164.23          7.20   \n",
       "534 2023-02-17   11284939.90        42.37        3.46  209.22          6.41   \n",
       "507 2023-01-13    9710842.80        36.15        3.54  163.71          7.20   \n",
       "\n",
       "     Holiday_Flag  Anomaly  Sales_Amount_Upper  Sales_Amount_Lower  ...  \\\n",
       "438             0        0          7688144.87          6336700.40  ...   \n",
       "416             1        0         10296654.30          8236027.05  ...   \n",
       "532             0        0         12269936.54          9419068.75  ...   \n",
       "534             0        1         11179403.79          9118776.54  ...   \n",
       "507             0        1         12943328.33         10092460.55  ...   \n",
       "\n",
       "     Unemployment_6  Unemployment_5  Unemployment_4  Unemployment_3  \\\n",
       "438            9.29            9.29            9.29            9.29   \n",
       "416            7.10            7.10            7.10            7.10   \n",
       "532            7.20            7.20            7.20            7.20   \n",
       "534            6.41            6.41            6.41            6.41   \n",
       "507            7.28            7.28            7.28            7.28   \n",
       "\n",
       "     Unemployment_2  Unemployment_1  Week_Of_Month  Month  Quarter  Year  \n",
       "438            9.29            9.29              2     10        4  2022  \n",
       "416            7.10            7.10              2      9        3  2022  \n",
       "532            7.20            7.20              3      2        1  2023  \n",
       "534            6.41            6.41              3      2        1  2023  \n",
       "507            7.28            7.20              2      1        1  2023  \n",
       "\n",
       "[5 rows x 275 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a51679a-f5cb-4a00-89d8-859f1fe6755d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "50b62622-e147-4d34-b59f-14feefcc7f51",
   "metadata": {},
   "source": [
    "### Split Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "290e89fd-9451-40d2-a171-d8979e7dd67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(251, 64, 135, 450, 450)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(np.floor(data.shape[0]*0.8*0.7))\n",
    "val_size = int(np.floor(data.shape[0]*0.7) - train_size)\n",
    "test_size = int(data.shape[0] - train_size - val_size)\n",
    "\n",
    "train_size, val_size, test_size, train_size + val_size + test_size, data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3b1a44f-1e90-4866-b67d-a289b58681ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 275),\n",
       " (64, 275),\n",
       " (135, 275),\n",
       " Anomaly\n",
       " 0    131\n",
       " 1      4\n",
       " Name: count, dtype: int64)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.iloc[:train_size]\n",
    "val_data = data.iloc[train_size:train_size+val_size]\n",
    "test_data = data.iloc[:test_size]\n",
    "\n",
    "train_data.shape, val_data.shape, test_data.shape, test_data['Anomaly'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f987ae60-f3a9-46c3-96a6-70ef4a35797f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((251, 273), (64, 273), (115, 273), (20, 273))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_Xy(data, drop_cols, target_col):\n",
    "    X = data.drop(drop_cols, axis=1)\n",
    "    y = data['Anomaly']\n",
    "    return X,y\n",
    "\n",
    "\n",
    "    \n",
    "drop_cols = ['Date', 'Anomaly']  #, 'Sales_Amount_Upper', 'Sales_Amount_Lower'\n",
    "\n",
    "X_train, y_train = get_Xy(train_data, drop_cols, 'Anomaly')\n",
    "X_val, y_val = get_Xy(val_data, drop_cols, 'Anomaly')\n",
    "X_test, y_test = get_Xy(test_data, drop_cols, 'Anomaly')\n",
    "X_test2, y_test2 = X_test.iloc[-20:], y_test[-20:]\n",
    "X_test, y_test = X_test.iloc[:-20], y_test[:-20]\n",
    "\n",
    "X_train.shape, X_val.shape, X_test.shape, X_test2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "984f70eb-a019-4b7a-ade8-e85d5565490a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Sales_Amount_Upper</th>\n",
       "      <th>Sales_Amount_Lower</th>\n",
       "      <th>State</th>\n",
       "      <th>Weekly_Sales_52</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment_6</th>\n",
       "      <th>Unemployment_5</th>\n",
       "      <th>Unemployment_4</th>\n",
       "      <th>Unemployment_3</th>\n",
       "      <th>Unemployment_2</th>\n",
       "      <th>Unemployment_1</th>\n",
       "      <th>Week_Of_Month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>7444909.07</td>\n",
       "      <td>34.24</td>\n",
       "      <td>3.13</td>\n",
       "      <td>164.55</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0</td>\n",
       "      <td>7850346.28</td>\n",
       "      <td>6498901.81</td>\n",
       "      <td>3</td>\n",
       "      <td>8161946.14</td>\n",
       "      <td>...</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6705436.37</td>\n",
       "      <td>32.87</td>\n",
       "      <td>3.12</td>\n",
       "      <td>168.75</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0</td>\n",
       "      <td>6946379.76</td>\n",
       "      <td>5725595.20</td>\n",
       "      <td>4</td>\n",
       "      <td>6575770.40</td>\n",
       "      <td>...</td>\n",
       "      <td>8.85</td>\n",
       "      <td>8.85</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>9985425.58</td>\n",
       "      <td>33.06</td>\n",
       "      <td>2.99</td>\n",
       "      <td>202.16</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>10587907.70</td>\n",
       "      <td>8527280.46</td>\n",
       "      <td>1</td>\n",
       "      <td>10397622.73</td>\n",
       "      <td>...</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weekly_Sales  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
       "260    7444909.07        34.24        3.13  164.55          9.49   \n",
       "261    6705436.37        32.87        3.12  168.75          8.68   \n",
       "262    9985425.58        33.06        2.99  202.16          7.20   \n",
       "\n",
       "     Holiday_Flag  Sales_Amount_Upper  Sales_Amount_Lower  State  \\\n",
       "260             0          7850346.28          6498901.81      3   \n",
       "261             0          6946379.76          5725595.20      4   \n",
       "262             0         10587907.70          8527280.46      1   \n",
       "\n",
       "     Weekly_Sales_52  ...  Unemployment_6  Unemployment_5  Unemployment_4  \\\n",
       "260       8161946.14  ...            9.67            9.67            9.49   \n",
       "261       6575770.40  ...            8.85            8.85            8.68   \n",
       "262      10397622.73  ...            7.40            7.40            7.20   \n",
       "\n",
       "     Unemployment_3  Unemployment_2  Unemployment_1  Week_Of_Month  Month  \\\n",
       "260            9.49            9.49            9.49              1      2   \n",
       "261            8.68            8.68            8.68              1      2   \n",
       "262            7.20            7.20            7.20              1      2   \n",
       "\n",
       "     Quarter  Year  \n",
       "260        1  2022  \n",
       "261        1  2022  \n",
       "262        1  2022  \n",
       "\n",
       "[3 rows x 273 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fdbb7f2-3dcf-4a13-8cf6-a23dcc94316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Split the data into features and target variable \n",
    "# # Split into Train and Test sets RANDOMLY\n",
    "# X = data.drop(['Date', 'Anomaly', 'Sales_Amount_Upper', 'Sales_Amount_Lower'], axis=1)\n",
    "# y = data['Anomaly']\n",
    "\n",
    "# ## TODO: Split as per the date instead of ramdom\n",
    "\n",
    "\n",
    "# # Perform train-test split (80:20 ratio)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Further split the training data into train and validation sets\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Display the shapes of the datasets after splitting\n",
    "# X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fe03e8c3-1b83-446a-9971-7e7e05f02c0e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>Holiday_Flag</th>\n",
       "      <th>Sales_Amount_Upper</th>\n",
       "      <th>Sales_Amount_Lower</th>\n",
       "      <th>State</th>\n",
       "      <th>Weekly_Sales_52</th>\n",
       "      <th>...</th>\n",
       "      <th>Unemployment_6</th>\n",
       "      <th>Unemployment_5</th>\n",
       "      <th>Unemployment_4</th>\n",
       "      <th>Unemployment_3</th>\n",
       "      <th>Unemployment_2</th>\n",
       "      <th>Unemployment_1</th>\n",
       "      <th>Week_Of_Month</th>\n",
       "      <th>Month</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>260</th>\n",
       "      <td>7444909.07</td>\n",
       "      <td>34.24</td>\n",
       "      <td>3.13</td>\n",
       "      <td>164.55</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0</td>\n",
       "      <td>7850346.28</td>\n",
       "      <td>6498901.81</td>\n",
       "      <td>3</td>\n",
       "      <td>8161946.14</td>\n",
       "      <td>...</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.67</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>9.49</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6705436.37</td>\n",
       "      <td>32.87</td>\n",
       "      <td>3.12</td>\n",
       "      <td>168.75</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0</td>\n",
       "      <td>6946379.76</td>\n",
       "      <td>5725595.20</td>\n",
       "      <td>4</td>\n",
       "      <td>6575770.40</td>\n",
       "      <td>...</td>\n",
       "      <td>8.85</td>\n",
       "      <td>8.85</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>8.68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>9985425.58</td>\n",
       "      <td>33.06</td>\n",
       "      <td>2.99</td>\n",
       "      <td>202.16</td>\n",
       "      <td>7.20</td>\n",
       "      <td>0</td>\n",
       "      <td>10587907.70</td>\n",
       "      <td>8527280.46</td>\n",
       "      <td>1</td>\n",
       "      <td>10397622.73</td>\n",
       "      <td>...</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.40</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 273 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Weekly_Sales  Temperature  Fuel_Price     CPI  Unemployment  \\\n",
       "260    7444909.07        34.24        3.13  164.55          9.49   \n",
       "261    6705436.37        32.87        3.12  168.75          8.68   \n",
       "262    9985425.58        33.06        2.99  202.16          7.20   \n",
       "\n",
       "     Holiday_Flag  Sales_Amount_Upper  Sales_Amount_Lower  State  \\\n",
       "260             0          7850346.28          6498901.81      3   \n",
       "261             0          6946379.76          5725595.20      4   \n",
       "262             0         10587907.70          8527280.46      1   \n",
       "\n",
       "     Weekly_Sales_52  ...  Unemployment_6  Unemployment_5  Unemployment_4  \\\n",
       "260       8161946.14  ...            9.67            9.67            9.49   \n",
       "261       6575770.40  ...            8.85            8.85            8.68   \n",
       "262      10397622.73  ...            7.40            7.40            7.20   \n",
       "\n",
       "     Unemployment_3  Unemployment_2  Unemployment_1  Week_Of_Month  Month  \\\n",
       "260            9.49            9.49            9.49              1      2   \n",
       "261            8.68            8.68            8.68              1      2   \n",
       "262            7.20            7.20            7.20              1      2   \n",
       "\n",
       "     Quarter  Year  \n",
       "260        1  2022  \n",
       "261        1  2022  \n",
       "262        1  2022  \n",
       "\n",
       "[3 rows x 273 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2dd33a7-daa1-46bd-8012-50aab1121573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
       "       'Holiday_Flag', 'Sales_Amount_Upper', 'Sales_Amount_Lower', 'State',\n",
       "       'Weekly_Sales_52',\n",
       "       ...\n",
       "       'Unemployment_6', 'Unemployment_5', 'Unemployment_4', 'Unemployment_3',\n",
       "       'Unemployment_2', 'Unemployment_1', 'Week_Of_Month', 'Month', 'Quarter',\n",
       "       'Year'],\n",
       "      dtype='object', length=273)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f331e24e-e98f-48fe-bd84-bdad74f9ee53",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e367f5b-659e-421c-b932-ae33f2bd99ff",
   "metadata": {},
   "source": [
    "### Add more features:\n",
    "* rolling statistics for weekly sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "34c0449b-c819-4503-bf88-06e6f55ff286",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data[f'{col}_lag_{lag}'] = data[f'{col}_lag_{lag}'].bfill()\n",
    "# # Calculate rolling statistics\n",
    "# window = 4  # Window size for rolling statistics\n",
    "# data['Rolling_Mean_Weekly_Sales'] = data['Weekly_Sales'].rolling(window=window).mean()  # Rolling mean of weekly sales\n",
    "# data['Rolling_Mean_Weekly_Sales'] = data['Rolling_Mean_Weekly_Sales'].bfill() # Backfill NAs, TODO: Change this to see if results improve\n",
    "\n",
    "# data['Rolling_Std_Weekly_Sales'] = data['Weekly_Sales'].rolling(window=window).std()  # Rolling standard deviation of weekly sales\n",
    "# data['Rolling_Std_Weekly_Sales'] = data['Rolling_Std_Weekly_Sales'].bfill()\n",
    "\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0cccf01-fdc0-4ec2-9757-bcb9a2181466",
   "metadata": {},
   "source": [
    "### Resampling technique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ec3116-4693-43c2-b54b-76bc3a5d805f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# from imblearn.under_sampling import RandomUnderSampler\n",
    "# from imblearn.pipeline import make_pipeline\n",
    "\n",
    "# # Define the resampling strategy using a pipeline\n",
    "# resample_pipeline = make_pipeline(SMOTE(random_state=42), RandomUnderSampler(random_state=42))\n",
    "\n",
    "# # Apply the resampling strategy to the training data\n",
    "# X_resampled, y_resampled = resample_pipeline.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923c564-fad3-47ac-bb3f-0dcd8358ecfe",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f262bced-da22-4142-a42c-47796aefc507",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the XGBoost model\n",
    "xgb_model = XGBClassifier(objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# Define the hyperparameters grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.5, 0.8],\n",
    "    'learning_rate': [0.1, 0.15, 0.2, 0.25],\n",
    "    'colsample_bytree': [0.5, 0.8],\n",
    "    # 'reg_alpha': [0, 0.5, 1],\n",
    "    # 'reg_lambda': [0, 0.5, 1],\n",
    "    # 'gamma': [0, 0.2],\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the data (do not run this line if you only want the code for setting up the grid search)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Display the grid search results\n",
    "print(\"Grid Search Results:\")\n",
    "print(grid_search.cv_results_)\n",
    "\n",
    "# Retrieve the best model from the grid search\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"\\nBest Model:\")\n",
    "print(best_model)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "574aa92d-03f5-4860-b4d9-ada35e2884ed",
   "metadata": {},
   "source": [
    "# Make predictions on the validation set\n",
    "y_val_pred = best_model.predict(X_val)\n",
    "\n",
    "# Evaluate the model performance on the validation set\n",
    "validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "validation_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", validation_accuracy)\n",
    "print(\"Validation Report:\")\n",
    "print(validation_report)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_test_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d54288c-1f0d-4495-beb1-51ef1678a125",
   "metadata": {},
   "source": [
    "Validation Accuracy: 0.6936936936936937\n",
    "Validation Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.69      1.00      0.81        74\n",
    "           1       1.00      0.08      0.15        37\n",
    "\n",
    "    accuracy                           0.69       111\n",
    "   macro avg       0.84      0.54      0.48       111\n",
    "weighted avg       0.79      0.69      0.59       111"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36ba5c81-7022-4e44-8d41-759209b55ec1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# print(best_model)\n",
    "# Get the parameters of the trained model\n",
    "params = best_model.get_params()\n",
    "\n",
    "# Print all the parameters\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4b5304-c340-4fad-bcc7-a08e2a775d79",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "14af940a-9c31-4c4c-9524-f1c49f9c512c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
       "       'Holiday_Flag', 'Sales_Amount_Upper', 'Sales_Amount_Lower', 'State',\n",
       "       'Weekly_Sales_52',\n",
       "       ...\n",
       "       'Unemployment_6', 'Unemployment_5', 'Unemployment_4', 'Unemployment_3',\n",
       "       'Unemployment_2', 'Unemployment_1', 'Week_Of_Month', 'Month', 'Quarter',\n",
       "       'Year'],\n",
       "      dtype='object', length=273)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "37959212-eb11-43d6-af5a-2b5431aff3b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8125\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.93      0.90        56\n",
      "           1       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.81        64\n",
      "   macro avg       0.43      0.46      0.45        64\n",
      "weighted avg       0.76      0.81      0.78        64\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'XGBmodel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(validation_report)\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# As a final step we will use the best model from the validation step to predict the anomalies on test set.\u001b[39;00m\n\u001b[1;32m---> 26\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m \u001b[43mXGBmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\u001b[39;00m\n\u001b[0;32m     29\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m [\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m prediction\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m prediction \u001b[38;5;129;01min\u001b[39;00m y_pred_test]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'XGBmodel' is not defined"
     ]
    }
   ],
   "source": [
    "# Define a narrower set of hyperparameters\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 5,\n",
    "    'learning_rate': 0.2,\n",
    "    'subsample': 0.5,\n",
    "    'colsample_bytree': 0.8,\n",
    "}\n",
    "\n",
    "# Train the XGBoost model with the reduced set of hyperparameters\n",
    "model = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Evaluate the model performance on the validation set\n",
    "validation_accuracy = accuracy_score(y_val, y_val_pred)\n",
    "validation_report = classification_report(y_val, y_val_pred)\n",
    "\n",
    "print(\"Validation Accuracy:\", validation_accuracy)\n",
    "print(\"Validation Report:\")\n",
    "print(validation_report)\n",
    "\n",
    "# As a final step we will use the best model from the validation step to predict the anomalies on test set.\n",
    "y_pred_test = XGBmodel.predict(X_test)\n",
    "\n",
    "# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "y_pred_test = [1 if prediction==-1 else 0 for prediction in y_pred_test]\n",
    "print(\"###\"*50)\n",
    "# Print the F1-score on Test set\n",
    "print(\"Test F1-score\\n\", classification_report(y_test, y_pred_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae84963-a6bf-434c-b6d0-3f1b7cdd9960",
   "metadata": {},
   "source": [
    "Validation Accuracy: 0.8070175438596491\n",
    "Validation Report:\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.80      0.96      0.87        79\n",
    "           1       0.84      0.46      0.59        35\n",
    "\n",
    "    accuracy                           0.81       114\n",
    "   macro avg       0.82      0.71      0.73       114\n",
    "weighted avg       0.81      0.81      0.79       114"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12331985-123a-49eb-ae8d-d2c05b40e4ea",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# print(best_model)\n",
    "# Get the parameters of the trained model\n",
    "params = model.get_params()\n",
    "\n",
    "# Print all the parameters\n",
    "for key, value in params.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19145be0-d6e8-4101-babd-c180a672c8e0",
   "metadata": {},
   "source": [
    "### Forward Chaining or Rolling Window Split \"Walk Forward Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a19d96e7-338a-41c4-a912-3eea3211515a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff176c-4be3-41c9-85bd-1f19d26bd04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a narrower set of hyperparameters\n",
    "params = {\n",
    "    'n_estimators': 100,\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'subsample': 0.5,\n",
    "    # 'colsample_bytree': 0.8,\n",
    "}\n",
    "\n",
    "# Define model\n",
    "XGBmodel = XGBClassifier(**params, objective=\"binary:logistic\", random_state=42)\n",
    "\n",
    "# Define the number of splits\n",
    "n_splits = 3\n",
    "\n",
    "# Initialize TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Loop over each split and train-validation the model\n",
    "for train_index, validation_index in tscv.split(train_data):\n",
    "    X_train_split, X_validation_split = train_data.iloc[train_index], train_data.iloc[validation_index]\n",
    "    \n",
    "    # Train the model\n",
    "    XGBmodel.fit(X_train_split.drop(['Anomaly','Date'], axis=1), X_train_split['Anomaly'])\n",
    "    \n",
    "    # Predict the anomalies on validation set\n",
    "    y_pred = XGBmodel.predict(X_validation_split.drop(['Anomaly','Date'], axis=1))\n",
    "    \n",
    "    # Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "    y_pred = [1 if prediction==-1 else 0 for prediction in y_pred]\n",
    "    \n",
    "    # Print the F1-score for each validation\n",
    "    print(\"F1-score for each validation\", f1_score(X_validation_split['Anomaly'], y_pred))\n",
    "\n",
    "# As a final step we will use the best model from the validation step to predict the anomalies on test set.\n",
    "y_pred_test = XGBmodel.predict(test_data.drop(['Anomaly','Date'], axis=1))\n",
    "\n",
    "# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "y_pred_test = [1 if prediction==-1 else 0 for prediction in y_pred_test]\n",
    "\n",
    "# Print the F1-score on Test set\n",
    "print(\"Test F1-score\", classification_report(test_data['Anomaly'], y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7df025-cb67-4c85-a1ff-8501aae46d56",
   "metadata": {},
   "source": [
    "## Train Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3463f2-0013-4473-99a1-127dea4f8f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "IFmodel = IsolationForest(contamination=0.01)\n",
    "\n",
    "# Define the number of splits\n",
    "n_splits = 3\n",
    "\n",
    "# Initialize TimeSeriesSplit object\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "# Loop over each split and train-validation the model\n",
    "for train_index, validation_index in tscv.split(train_data):\n",
    "    X_train_split, X_validation_split = train_data.iloc[train_index], train_data.iloc[validation_index]\n",
    "    # print(\"train_index, validation_index\",train_index, validation_index)\n",
    "    # print(X_train.shape, X_validation.shape)\n",
    "    # Train the model\n",
    "    IFmodel.fit(X_train_split.drop(['Anomaly','Date'], axis=1))\n",
    "    \n",
    "    # Predict the anomalies on validation set\n",
    "    y_pred = IFmodel.predict(X_validation_split.drop(['Anomaly','Date'], axis=1))\n",
    "    \n",
    "    # Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "    y_pred = [1 if prediction==-1 else 0 for prediction in y_pred]\n",
    "    \n",
    "    # Print the F1-score for each validation\n",
    "    print(\"F1-score for each validation\", f1_score(X_validation_split['Anomaly'], y_pred))\n",
    "\n",
    "# As a final step we will use the best model from the validation step to predict the anomalies on test set.\n",
    "y_pred_test = IFmodel.predict(test_data.drop(['Anomaly','Date'], axis=1))\n",
    "\n",
    "# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "y_pred_test = [1 if prediction==-1 else 0 for prediction in y_pred_test]\n",
    "\n",
    "# Print the F1-score on Test set\n",
    "print(\"Test F1-score\", classification_report(test_data['Anomaly'], y_pred_test))\n",
    "test_data['Anomaly_pred'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b48681b-07a9-4379-980a-44ef1138aee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "IFmodel = IsolationForest(contamination=0.01)\n",
    "\n",
    "# X_train, y_train\n",
    "\n",
    "IFmodel.fit(X_train)\n",
    "\n",
    "# Predict the anomalies on validation set\n",
    "y_pred = IFmodel.predict(X_val)\n",
    "\n",
    "# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "y_pred = [1 if prediction==-1 else 0 for prediction in y_pred]\n",
    "\n",
    "# Print the F1-score for each validation\n",
    "print(\"F1-score validation\", f1_score(y_val, y_pred))\n",
    "\n",
    "# As a final step we will use the best model from the validation step to predict the anomalies on test set.\n",
    "y_pred_test = IFmodel.predict(X_test)\n",
    "\n",
    "# Change the anomaly labels (from -1, 1) to (1, 0) similar to 'Anomaly' column\n",
    "y_pred_test = [1 if prediction==-1 else 0 for prediction in y_pred_test]\n",
    "\n",
    "# Print the F1-score on Test set\n",
    "print(\"Test F1-score\", classification_report(y_test, y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e67fec-dd36-47fa-8e7e-6ed06bbc4ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be968688-ebe1-41b8-8cd2-3b7e46e308eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da80335f-22fa-411f-89d2-c365d84cf65f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e037db6-d980-4b16-b0f2-9ddd6d705f50",
   "metadata": {},
   "source": [
    "## Saving model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732076b-bcb3-4e52-b282-c581e98f38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "joblib.dump(model, model_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aa02fdb-ce5a-4048-8891-d61637405622",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33804608-ad0d-443b-b3c8-092c1c8c146e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model from file\n",
    "loaded_model = joblib.load(model_file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb81627-ee88-4648-a056-02fa1c2bc12b",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05b6539-5929-47a0-8242-92b879dda610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model performance on the test set\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "test_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n",
    "print(\"Test Report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0310f2-1d63-4fff-b31c-d656c61f2f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_test_pred2 = model.predict(X_test2)\n",
    "\n",
    "# Evaluate the model performance on the test set\n",
    "test_accuracy = accuracy_score(y_test2, y_test_pred2)\n",
    "test_report = classification_report(y_test2, y_test_pred2)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n",
    "print(\"Test Report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5266178-a3f5-45d3-893e-8613520f6f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_test_pred = model.predict(X_test2)\n",
    "\n",
    "# Evaluate the model performance on the test set\n",
    "test_accuracy = accuracy_score(y_test2, y_test_pred)\n",
    "test_report = classification_report(y_test2, y_test_pred)\n",
    "\n",
    "print(\"\\nTest Accuracy:\", test_accuracy)\n",
    "print(\"Test Report:\")\n",
    "print(test_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d5ccb-cd98-47b3-89aa-4e85db90c698",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test2.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005f1ec-ab4f-4341-80b9-b02f2edf54fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.shape, len(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f4973-770a-44d5-b173-e0a4dcb09544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_data['Anomaly_pred'] = y_test_pred\n",
    "test_data[test_data['Anomaly']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7aa34c1-ff92-4355-8e5e-5f6b8a84a496",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_df = X_test\n",
    "# test_df['Anomaly'] = y_test\n",
    "# test_df['Anomaly_pred'] = y_test_pred\n",
    "test_data[(test_data['Anomaly']==1) & (test_data['State']==2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652bbb44-fbd4-4e1d-b6cb-456e28b3c3aa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "for state in test_data['State'].unique():\n",
    "    # Create a Figure for the current state\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Filter the DataFrame for the current state\n",
    "    state_df = test_data[test_data['State'] == state]\n",
    "    state_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Create a Scatter plot for the target values\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=state_df.index,\n",
    "        y=state_df[target],\n",
    "        mode='lines+markers',\n",
    "        name=target,\n",
    "        line=dict(color='black', dash='dash')\n",
    "    ))\n",
    "    \n",
    "    # Filter the data where anomalies are present (Anomaly == 1)\n",
    "    anomalies = state_df[state_df['Anomaly'] == 1]\n",
    "    \n",
    "    # Add a scatter trace for the anomaly points\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=anomalies.index,\n",
    "        y=anomalies[target],\n",
    "        mode='markers',\n",
    "        name='Anomaly',\n",
    "        marker=dict(color='red', size=10, symbol='x')\n",
    "    ))\n",
    "    \n",
    "    # Update layout settings\n",
    "    fig.update_layout(\n",
    "        title=f\"Anomalies for {state}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=target,\n",
    "        template=\"plotly_white\",\n",
    "        autosize=False,\n",
    "        width=1200,\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "     # Create a Figure for the current state\n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Filter the DataFrame for the current state\n",
    "    state_df = test_data[test_data['State'] == state]\n",
    "    state_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Create a Scatter plot for the target values\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=state_df.index,\n",
    "        y=state_df[target],\n",
    "        mode='lines+markers',\n",
    "        name=target,\n",
    "        line=dict(color='black', dash='dash')\n",
    "    ))\n",
    "    \n",
    "    # Filter the data where anomalies are present (Anomaly == 1)\n",
    "    anomalies = state_df[state_df['Anomaly_pred'] == 1]\n",
    "    \n",
    "    # Add a scatter trace for the anomaly points\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=anomalies.index,\n",
    "        y=anomalies[target],\n",
    "        mode='markers',\n",
    "        name='Anomaly Pred',\n",
    "        marker=dict(color='red', size=10, symbol='x')\n",
    "    ))\n",
    "    \n",
    "    # Update layout settings\n",
    "    fig.update_layout(\n",
    "        title=f\"Predicted Anomalies for {state}\",\n",
    "        xaxis_title=\"Date\",\n",
    "        yaxis_title=target,\n",
    "        template=\"plotly_white\",\n",
    "        autosize=False,\n",
    "        width=1200,\n",
    "        height=400\n",
    "    )\n",
    "    \n",
    "    # Show the plot\n",
    "    fig.show()\n",
    "\n",
    "    print(\"####\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc743af3-9cf1-47ec-be34-e9de74e6e97b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b0586c90-c86a-4671-bb5c-49d7cbbb82fa",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae4ea9-38cb-4fa5-acf6-fa899eb7aa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the new dataset for inference\n",
    "inference_data = pd.read_csv(inference_file, usecols=['Date','Weekly_Sales', 'Temperature', 'Fuel_Price', 'CPI', 'Unemployment',\n",
    "       'Holiday_Flag','State'])\n",
    "\n",
    "# Convert the 'Date' column to datetime format\n",
    "# inference_data['Date'] = pd.to_datetime(inference_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "inference_data = standardize_date_col(inference_data, 'Date')\n",
    "\n",
    "# Get the saved Encoder for State column \n",
    "encoder = joblib.load(state_encoder)\n",
    "inference_data['State'] = encoder.fit_transform(inference_data['State'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff6d005-4e5b-48fa-a59a-5a9239971740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Date'].max(), inference_data['Date'].min(), inference_data['Date'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb1bf03-2a01-49d0-96b4-770dac7e24da",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = inference_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3602f1-c1f9-476e-bdaa-d912323f026b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate the next four Fridays after 2023-10-27\n",
    "start_date = pd.to_datetime('2023-10-27')\n",
    "next_fridays = [start_date + pd.DateOffset(weeks=i) for i in range(1, 5)]\n",
    "\n",
    "# Function to generate synthetic data with a fluctuation of 5%\n",
    "def generate_synthetic_data(base_data, date):\n",
    "    # Copy the base data to start with\n",
    "    synthetic_data = base_data.copy()\n",
    "    # Update the date to the current date\n",
    "    synthetic_data['Date'] = date.strftime('%Y-%m-%d')\n",
    "    # Apply a fluctuation of ±5% to the numeric columns\n",
    "    fluctuation = np.random.uniform(-0.05, 0.05)\n",
    "    synthetic_data['Weekly_Sales'] *= (1 + np.abs(fluctuation*100))\n",
    "    synthetic_data['Temperature'] *= (1 + fluctuation)\n",
    "    synthetic_data['Fuel_Price'] *= (1 + fluctuation)\n",
    "    synthetic_data['CPI'] *= (1 + fluctuation)\n",
    "    synthetic_data['Unemployment'] *= (1 + fluctuation)\n",
    "    # Return the synthetic data\n",
    "    return synthetic_data\n",
    "\n",
    "# List to hold synthetic data\n",
    "synthetic_data_list = inference_data\n",
    "\n",
    "# Generate synthetic data for each next Friday\n",
    "for date in next_fridays:\n",
    "    synthetic_data = generate_synthetic_data(synthetic_data_list, date)\n",
    "    inference_data = pd.concat([inference_data, synthetic_data])\n",
    "\n",
    "# inference_data = synthetic_data_list\n",
    "# del synthetic_data_list\n",
    "\n",
    "# clean up the data:\n",
    "# Identify numeric columns\n",
    "numeric_columns = inference_data.select_dtypes(include=[int, float]).columns\n",
    "\n",
    "# Round the numeric values in these columns to 2 decimal places\n",
    "inference_data[numeric_columns] = inference_data[numeric_columns].round(2)\n",
    "\n",
    "inference_data.reset_index(inplace=True, drop=True)\n",
    "# Print the synthetic DataFrame\n",
    "inference_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309d7329-2a1d-45e8-9f29-cb3e2741941e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_data = standardize_date_col(inference_data, 'Date')\n",
    "inference_data_all = pd.concat([data[cols],inference_data])\n",
    "inference_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26957033-f8a0-4133-92e4-4472ac300d9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Sort the data by the 'Date' column in ascending order\n",
    "inference_data_all = inference_data_all.sort_values('Date')\n",
    "\n",
    "# Create lag features for the relevant columns\n",
    "print(groupby_cols, lag_columns)\n",
    "inference_data_all = get_lag_columns(inference_data_all, groupby_cols, lag_columns)\n",
    "\n",
    "inference_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f3bd5-558c-49e1-ae35-966a9acb96b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "inference_data_all[inference_data_all['Date']>='2023-10-27']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6666b2-9876-4358-b069-28d6fdae301e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the inference data back with lag values:\n",
    "inference_data = inference_data_all[inference_data_all['Date']>='2023-10-27']\n",
    "# Get week of the month value too before passing it to model\n",
    "inference_data = get_date_features(inference_data, 'Date')\n",
    "# inference_data['Week_Of_Month'] = inference_data['Date'].map(week_of_month)\n",
    "# Display the updated new dataset with lag features\n",
    "inference_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cc08c5-e51f-47aa-8492-ee032335e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54b72ac-219b-422f-a4d7-6d99ac4ded61",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1112863943\n",
    "\n",
    "inference_data['Weekly_Sales'] = 100\n",
    "inference_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd75582b-4e8e-4b2d-b3e5-f8f0689f5ec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Perform inference using the loaded model\n",
    "predictions = model.predict(inference_data.drop(columns=['Date']))\n",
    "\n",
    "# Display the predictions\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb4d8c8-8540-42f1-a9b7-665eae1518b2",
   "metadata": {},
   "source": [
    "## Saving inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15eb43b-1505-4100-942f-9b8f5455f763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "51e5b7aa-a18a-4f95-8f5e-d605e110d4a6",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
